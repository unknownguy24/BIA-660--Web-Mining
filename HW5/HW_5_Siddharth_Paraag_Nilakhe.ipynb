{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW 5: Clustering and Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">Each assignment needs to be completed independently. Never ever copy others' work (even with minor modification, e.g. changing variable names). Anti-Plagiarism software will be used to check all submissions. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you'll practice different text clustering methods. A dataset has been prepared for you:\n",
    "- `hw5_train.csv`: This file contains a list of documents. It's used for training models\n",
    "- `hw5_test`: This file contains a list of documents and their ground-truth labels (4 lables: 1,2,3,7). It's used for external evaluation. \n",
    "\n",
    "|Text| Label|\n",
    "|----|-------|\n",
    "|paraglider collides with hot air balloon ... | 1|\n",
    "|faa issues fire warning for lithium ... | 2|\n",
    "| .... |...|\n",
    "\n",
    "Sample outputs have been provided to you. Due to randomness, you may not get the exact result as shown here, but your result should be close if you tune the parameters carefully. Your taget is to `achieve above 70% F1 on the test dataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: K-Mean Clustering \n",
    "\n",
    "Define a function `cluster_kmean(train_text, test_text, text_label)` as follows:\n",
    "- Take three inputs: \n",
    "    - `train_text` is a list of documents for traing \n",
    "    - `test_text` is a list of documents for test\n",
    "    - `test_label` is the labels corresponding to documents in `test_text` \n",
    "- First generate `TFIDF` weights. You need to decide appropriate values for parameters such as `stopwords` and `min_df`:\n",
    "    - Keep or remove stopwords? Customized stop words? \n",
    "    - Set appropriate `min_df` to filter infrequent words\n",
    "- Use `KMeans` to cluster documents in `train_text` into 4 clusters. Here you need to decide the following parameters:\n",
    "    \n",
    "    - Distance measure: `cosine similarity`  or `Euclidean distance`? Pick the one which gives you better performance.  \n",
    "    - When clustering, be sure to  use sufficient iterations with different initial centroids to make sure clustering converge.\n",
    "- Test the clustering model performance using `test_label` as follows: \n",
    "  - Predict the cluster ID for each document in `test_text`.\n",
    "  - Apply `majority vote` rule to dynamically map the predicted cluster IDs to `test_label`. Note, you'd better not hardcode the mapping, because cluster IDs may be assigned differently in each run. (hint: if you use pandas, look for `idxmax` function).\n",
    "  - Print out the cross tabluation between cluster ids and class labels\n",
    "  - print out the classification report for the test subset \n",
    "  \n",
    "  \n",
    "- This function has no return. Print out the classification report. \n",
    "\n",
    "\n",
    "- Briefly discuss:\n",
    "    - Which distance measure is better and why it is better. \n",
    "    - Could you assign a meaningful name to each cluster? Discuss how you interpret each cluster.\n",
    "- Write your analysis in a pdf file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import metrics, mixture\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.cluster import KMeansClusterer, cosine_distance\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Add your import statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       No desire to visit mother in jail, am I a bad ...\n",
       "1       what types of desirable products/materials can...\n",
       "2       what is teleportation? why an unknown indian i...\n",
       "3       Do you have to read the whole Bible to get int...\n",
       "4       6 yr old son with a Deviated Septum!!!!?\\nMy s...\n",
       "                              ...                        \n",
       "1269    most ghetto.?\\nI'm aware that ghetto is an ign...\n",
       "1270    Does anyone know about free on-line Wiccan new...\n",
       "1271    total number of cell divisions from the beginn...\n",
       "1272    What should I do to relieve my coughing and di...\n",
       "1273    what does this sound like to you.........?\\nso...\n",
       "Name: text, Length: 1274, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"hw5_train.csv\")\n",
    "train.head()\n",
    "\n",
    "test = pd.read_csv(\"hw5_test.csv\")\n",
    "test.head()\n",
    "\n",
    "test_text = test[\"text\"]\n",
    "test_label = test[\"label\"]\n",
    "test_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_kmean(train, test_text, test_label):\n",
    "    \n",
    "   # Add your code\n",
    "    tfidf_vect = TfidfVectorizer(stop_words = \"english\", min_df = 5)\n",
    "    dtm = tfidf_vect.fit_transform(train)\n",
    "    print(dtm.shape)\n",
    "    \n",
    "    num_clusters = 4\n",
    "    \n",
    "    clusterer = KMeansClusterer(num_clusters, cosine_distance, repeats = 20)\n",
    "    clusters = clusterer.cluster(dtm.toarray(), assign_clusters = True)\n",
    "    test_dtm = tfidf_vect.transform(test_text)\n",
    "    predicted = [clusterer.classify(v) for v in test_dtm.toarray()]\n",
    "    \n",
    "    confusion_df = pd.DataFrame(list(zip(test_label, predicted)), columns = [\"label\", \"cluster\"])\n",
    "    crosstab = pd.crosstab(index = confusion_df.cluster, columns = confusion_df.label)\n",
    "    print('Crosstab of Kmean \\n',crosstab)\n",
    "    \n",
    "    clusters_dict = crosstab.idxmax(axis = 'columns')\n",
    "    predicted_targets = [clusters_dict[i] for i in predicted]\n",
    "    \n",
    "    print('\\n Classification Report of Kmean\\n',metrics.classification_report(test_label, predicted_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000, 6861)\n",
      "Crosstab of Kmean \n",
      " label      1    2    3    7\n",
      "cluster                    \n",
      "0          7  223   27    7\n",
      "1         33   30   21  199\n",
      "2         61   48  293   45\n",
      "3        231   13   14   22\n",
      "\n",
      " Classification Report of Kmean\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.82      0.70      0.75       332\n",
      "           2       0.84      0.71      0.77       314\n",
      "           3       0.66      0.83      0.73       355\n",
      "           7       0.70      0.73      0.72       273\n",
      "\n",
      "    accuracy                           0.74      1274\n",
      "   macro avg       0.76      0.74      0.74      1274\n",
      "weighted avg       0.76      0.74      0.74      1274\n",
      "\n",
      "CPU times: total: 8min 56s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_kmean(train[\"text\"], test_text, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_kmean(train[\"text\"], test_text, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: Clustering by Gaussian Mixture Model\n",
    "\n",
    "In this task, you'll re-do the clustering using a Gaussian Mixture Model. Call this function  `cluster_gmm(train_text, test_text, text_label)`. \n",
    "\n",
    "Write your analysis on the following:\n",
    "- How did you pick the parameters such as the number of clusters, variance type etc.?\n",
    "- Compare to Kmeans in Q1, do you achieve better preformance by GMM? \n",
    "\n",
    "- Note, like KMean, be sure to use different initial means (i.e. `n_init` parameter) when fitting the model to achieve the model stability "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_gmm(train, test_text, test_label):\n",
    "    \n",
    "    # Add your code\n",
    "    tfidf_vect = TfidfVectorizer(stop_words = \"english\", min_df = 5)\n",
    "    dtm = tfidf_vect.fit_transform(train)\n",
    "    lowest_bic = np.infty\n",
    "    best_gmm = None\n",
    "    n_components_range = range(2,8)\n",
    "    cv_types = ['spherical', 'tied', 'diag']\n",
    "    \n",
    "    for cv_type in cv_types:\n",
    "        for n_component in n_components_range:\n",
    "            gmm = mixture.GaussianMixture(n_components = n_component, covariance_type = cv_type, random_state = 42, n_init = 2)\n",
    "            gmm.fit(dtm.toarray())\n",
    "            bic = gmm.bic(dtm.toarray())\n",
    "            if bic < lowest_bic:\n",
    "                lowest_bic = bic\n",
    "                best_gmm = gmm\n",
    "                \n",
    "    test_dtm = tfidf_vect.transform(test_text)\n",
    "    predicted = best_gmm.predict(test_dtm.toarray())\n",
    "    \n",
    "    confusion_df = pd.DataFrame(list(zip(test_label, predicted)), columns = [\"label\", \"cluster\"])\n",
    "    crosstab = pd.crosstab(index = confusion_df.cluster, columns = confusion_df.label)\n",
    "    print('Crosstab \\n',crosstab)\n",
    "    \n",
    "    clusters_dict = crosstab.idxmax(axis = 'columns')\n",
    "    predicted_targets = [clusters_dict[i] for i in predicted]\n",
    "    \n",
    "    print('\\nClassification Report for GMM\\n',metrics.classification_report(test_label, predicted_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crosstab \n",
      " label      1    2    3    7\n",
      "cluster                    \n",
      "0         67    1    1    1\n",
      "1          0    0   27    2\n",
      "2          0   20    0    0\n",
      "3        160   37   97   77\n",
      "4         10   16  173    9\n",
      "5         11    3    5  116\n",
      "6         84  237   52   68\n",
      "\n",
      "Classification Report for GMM\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.51      0.68      0.59       332\n",
      "           2       0.56      0.82      0.66       314\n",
      "           3       0.84      0.56      0.68       355\n",
      "           7       0.86      0.42      0.57       273\n",
      "\n",
      "    accuracy                           0.63      1274\n",
      "   macro avg       0.69      0.62      0.62      1274\n",
      "weighted avg       0.69      0.63      0.63      1274\n",
      "\n",
      "CPU times: total: 1h 30min 2s\n",
      "Wall time: 12min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_gmm(train[\"text\"], test_text, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3: Clustering by LDA \n",
    "\n",
    "In this task, you'll re-do the clustering using LDA. Call this function `cluster_lda(train_text, test_text, text_label)`. \n",
    "\n",
    "However, since LDA returns topic mixture for each document, you `assign the topic with highest probability to each test document`, and then measure the performance as in Q1\n",
    "\n",
    "In addition, within the function, please print out the top 30 words for each topic\n",
    "\n",
    "Finally, please analyze the following:\n",
    "- Based on the top words of each topic, could you assign a meaningful name to each topic?\n",
    "- Although the test subset shows there are 4 clusters, without this information, how do you choose the number of topics? \n",
    "- Does your LDA model achieve better performance than KMeans or GMM?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_lda(train, test_text, test_label):\n",
    "    \n",
    "    # add your code\n",
    "    tf_vectorizer = CountVectorizer(min_df = 5, stop_words=list(stopwords.words('english')))\n",
    "    tf = tf_vectorizer.fit_transform(train.tolist()+test_text.tolist())\n",
    "    tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "    num_topics = 4\n",
    "    lda = LatentDirichletAllocation(n_components=num_topics, max_iter=30, verbose=1, evaluate_every=1, n_jobs=1, random_state=0).fit(tf)\n",
    "    num_top_words = 30\n",
    "    \n",
    "    for topic_idx, topic in enumerate(lda.components_):\n",
    "        print (\"Topic %d:\" % (topic_idx))\n",
    "        words=[tf_feature_names[i] for i in topic.argsort()[::-1][0:num_top_words]]\n",
    "        print(words)\n",
    "        print(\"\\n\")\n",
    "        \n",
    "    topic_assign = lda.transform(tf)\n",
    "    predicted = []\n",
    "    \n",
    "    for i in range(4000, 5274):\n",
    "        x = np.array(topic_assign[i])\n",
    "        predicted.append(np.argmax(x))\n",
    "        \n",
    "    confusion_df = pd.DataFrame(list(zip(test_label, predicted)), columns = [\"label\", \"cluster\"])\n",
    "    crosstab = pd.crosstab(index = confusion_df.cluster, columns = confusion_df.label)\n",
    "    print('Crosstab for LDA \\n',crosstab)\n",
    "    \n",
    "    clusters_dict = crosstab.idxmax(axis = 'columns')\n",
    "    predicted_targets = [clusters_dict[i] for i in predicted]\n",
    "    \n",
    "    print('\\n Classification for LDA \\n',metrics.classification_report(test_label, predicted_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\siddh\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 30, perplexity: 3429.2361\n",
      "iteration: 2 of max_iter: 30, perplexity: 3228.8556\n",
      "iteration: 3 of max_iter: 30, perplexity: 3051.9925\n",
      "iteration: 4 of max_iter: 30, perplexity: 2921.8382\n",
      "iteration: 5 of max_iter: 30, perplexity: 2836.1184\n",
      "iteration: 6 of max_iter: 30, perplexity: 2778.0444\n",
      "iteration: 7 of max_iter: 30, perplexity: 2735.2839\n",
      "iteration: 8 of max_iter: 30, perplexity: 2704.0936\n",
      "iteration: 9 of max_iter: 30, perplexity: 2682.0117\n",
      "iteration: 10 of max_iter: 30, perplexity: 2665.9518\n",
      "iteration: 11 of max_iter: 30, perplexity: 2653.2678\n",
      "iteration: 12 of max_iter: 30, perplexity: 2642.9544\n",
      "iteration: 13 of max_iter: 30, perplexity: 2634.0353\n",
      "iteration: 14 of max_iter: 30, perplexity: 2626.5810\n",
      "iteration: 15 of max_iter: 30, perplexity: 2620.8454\n",
      "iteration: 16 of max_iter: 30, perplexity: 2616.2603\n",
      "iteration: 17 of max_iter: 30, perplexity: 2612.0218\n",
      "iteration: 18 of max_iter: 30, perplexity: 2608.3306\n",
      "iteration: 19 of max_iter: 30, perplexity: 2605.2268\n",
      "iteration: 20 of max_iter: 30, perplexity: 2602.5069\n",
      "iteration: 21 of max_iter: 30, perplexity: 2600.1447\n",
      "iteration: 22 of max_iter: 30, perplexity: 2598.1423\n",
      "iteration: 23 of max_iter: 30, perplexity: 2596.3908\n",
      "iteration: 24 of max_iter: 30, perplexity: 2594.8772\n",
      "iteration: 25 of max_iter: 30, perplexity: 2593.5296\n",
      "iteration: 26 of max_iter: 30, perplexity: 2592.2648\n",
      "iteration: 27 of max_iter: 30, perplexity: 2591.0814\n",
      "iteration: 28 of max_iter: 30, perplexity: 2589.8911\n",
      "iteration: 29 of max_iter: 30, perplexity: 2588.6920\n",
      "iteration: 30 of max_iter: 30, perplexity: 2587.5671\n",
      "Topic 0:\n",
      "['water', 'weight', 'eat', 'would', 'one', 'energy', '10', 'fat', 'nthe', 'air', 'light', 'number', 'earth', 'diet', 'time', 'like', 'two', 'also', 'lose', 'need', 'get', '000', 'day', 'body', 'mass', 'go', 'help', 'know', 'speed', 'food']\n",
      "\n",
      "\n",
      "Topic 1:\n",
      "['also', 'body', 'may', 'doctor', 'blood', 'one', 'get', 'used', 'pain', 'like', 'skin', 'cause', 'help', 'could', 'cancer', 'use', 'take', 'see', 'disease', 'would', 'cells', 'normal', 'many', 'brain', 'two', 'people', 'called', 'symptoms', 'first', 'well']\n",
      "\n",
      "\n",
      "Topic 2:\n",
      "['god', 'people', 'one', 'would', 'believe', 'us', 'jesus', 'think', 'question', 'world', 'like', 'know', 'life', 'nhttp', 'bible', 'many', 'religion', 'com', 'www', 'man', 'say', 'time', 'christians', 'see', 'nthe', 'even', 'word', 'name', 'way', 'church']\n",
      "\n",
      "\n",
      "Topic 3:\n",
      "['get', 'like', 'know', 'would', 'want', 'good', 'people', 'one', 'need', 'think', 'help', 'go', 'time', 'work', 'make', 'really', 'way', 'find', 'much', 'could', 'something', 'take', 'money', 'feel', 'also', 'going', 'business', 'job', 'see', 'even']\n",
      "\n",
      "\n",
      "Crosstab for LDA \n",
      " label      1    2    3    7\n",
      "cluster                    \n",
      "0          3  177   46    8\n",
      "1          3   66  145    3\n",
      "2        221   27    8    8\n",
      "3        105   44  156  254\n",
      "\n",
      " Classification for LDA \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.67      0.74       332\n",
      "           2       0.76      0.56      0.65       314\n",
      "           3       0.67      0.41      0.51       355\n",
      "           7       0.45      0.93      0.61       273\n",
      "\n",
      "    accuracy                           0.63      1274\n",
      "   macro avg       0.68      0.64      0.63      1274\n",
      "weighted avg       0.69      0.63      0.62      1274\n",
      "\n",
      "CPU times: total: 1min 40s\n",
      "Wall time: 1min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cluster_lda(train[\"text\"], test_text, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cluster_lda(train[\"text\"], test_text, test_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 (Bonus): Topic Coherence and Separation\n",
    "\n",
    "For the LDA model you obtained at Q3, can you measure the coherence and separation of topics? Suppose you have the following topics:\n",
    "- Topic 1 keywords: business, money, company, pay, credit\n",
    "- Topic 2 keywords: energy, earth, gas, heat, sun\n",
    "\n",
    "Describe your ideas and implement them.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Due to randomness, you won't get the exact result\n",
    "    # as shown here, but your result should be close\n",
    "    # if you tune the parameters carefully\n",
    "    \n",
    "    train = pd.read_csv(\"hw5_train.csv\")\n",
    "    train.head()\n",
    "\n",
    "    test = pd.read_csv(\"hw5_test.csv\")\n",
    "    test.head()\n",
    "\n",
    "    test_text = test[\"text\"]\n",
    "    test_label = test[\"label\"]\n",
    "    \n",
    "    # Q1\n",
    "    cluster_kmean(train[\"text\"], test_text, test_label)\n",
    "            \n",
    "    # Q2\n",
    "    cluster_gmm(train[\"text\"], test_text, test_label)\n",
    "    \n",
    "    # Q2\n",
    "    cluster_lda(train[\"text\"], test_text, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
